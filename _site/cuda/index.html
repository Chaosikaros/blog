<!DOCTYPE html>
<html>
  <head>
  <title>CUDA开发笔记---向量运算对比 – Chaosikaros – Blog</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="最近开始学习CUDA。正式开始写代码前查了一些资料，对CUDA的印象就是擅长浮点数运算，缺点就是如果数据量不足够大，就不一定比CPU快。自己尝试了一些简单的对比后稍微有些理解了。

电脑配置：i7-670HQ，GTX970m，16G。

测试使用三个CUDA官方例子中的三维向量计算函数：

inline __host__ __device__ float3 normalize(float3 v)
{
    float invLen = rsqrtf(dot(v, v));
    return v * invLen;
}
inline __host__ __device__ float length(float3 v)
{
    return sqrtf(dot(v, v));
}
inline __host__ __device__ float dot(float3 a, float3 b)
{
    return a.x * b.x + a.y * b.y + a.z * b.z;
}

其中用到的其他函数是CUDA内置的sqrtf()和基于sqrtf()的rsqrtf()：平方根和平方根倒数

extern __CUDA_MATH_CRTIMP __DEVICE_FUNCTIONS_DECL__ __device_builtin__ float __cdecl sqrtf(float) __THROW; 
inline float rsqrtf(float x)
{
    return 1.0f / sqrtf(x);
}


输入： float3 a ：(99, 99, 99);
            float3 b ：(999, 999, 999);

时间单位ms。

第一次测试：使用以上三个函数计算100万次：normalize(a); length(a-b); dot(a,b).


  
    
       
      normalize(a)
      length(a-b)
      dot(a,b)
    
  
  
    
      CPU用时
      132
      141
      32
    
    
      CUDA用时
      None
      None
      None
    
  


CUDA下直接爆内存卡死。可能是我的配置扛不住连续一百万次cudaMemcpy()。

第二次测试：换成100次。


  
    
       
      normalize(a)
      length(a-b)
      dot(a,b)
    
  
  
    
      CPU用时
      0
      0
      0
    
    
      CUDA用时
      109
      14
      16
    
  


结论：差距巨大，按照第一次测试的结果估算，这种情况下CPU比CUDA快5333倍。

第三次测试：把单独输入换成数组一次输入。以下是不同大小数组的结果。


  
    
       
      CPU nor
      CUDA nor
      CPU len
      CUDA len
      CPU dot
      CUDA dot
    
  
  
    
      100
      0
      1
      0
      0
      0
      0
    
    
      1000
      0
      1
      0
      0
      0
      0
    
    
      10000
      1
      2
      1
      2
      0
      1
    
    
      100000
      14
      21
      14
      11
      3
      13
    
    
      1000000
      139
      143
      146
      103
      34
      107
    
    
      10000000
      1395
      1455
      1460
      1064
      361
      1056
    
    
      100000000
      14254
      17737
      14661
      14809
      3420
      10722
    
  


这次的结果就有意思了。10000长度以下差别不是很大，10万次以上CUDA的length(a-b)明显比CPU快，但其他的还是比不过CPU。一亿次时爆了内存，程序卡了，CUDA的length(a-b)优势也因为爆内存而消失了。

这就说明了CUDA的好几个特点。首先是输入量大的时候，把大量变量一起传给CUDA运算会比单个传快得多，因为单个传只用了CUDA的一个线程。在数据运算量不大的时候，CUDA和CPU差距也不大，甚至CPU还全面赶超CUDA。当数据量足够大时，CUDA的length(a-b)比CPU快了差不多一半，但其他的还是慢。

从函数上看，比dot的话，整数运算CUDA总是比CPU慢。 length函数中也是调用了dot，只不过是dot的两个输入相同。CUDA算dot应该比CPU慢，可是sqrtf()让CPU的length比它自己的dot运算慢了差不多四倍。输入a，b与a-b的量级差不多，所以差别就体现在sqrtf()上。CUDA的length就和它的dot差不多，应该是因为CUDA擅长浮点数运算，所以它的length就比CPU的快。

可是刚刚的结论似乎没法解释normalize上CUDA和CPU差距不是很大的事实。normalize只是比length多了一个倒数和乘法运算。理论上应该和length差不多，实际却比length慢一半。换个角度，对比两者的dot和normalize，CUDA的这两个运算差距不是很大，normalize只比dot慢了一半。而CPU的normalize几乎用了它dot的四倍时间。其中的差异应该还是rsqrtf()的sqrtf()造成的。

试了试嵌套调用normalize，第一次嵌套就比CPU快了一点。CPU/CUDA的时间比随着嵌套次数开始增加，1.04，1.07，1.18，1.13，1.17。normalize嵌套意义可能不大，因为嵌套之后每次运算过程都一样。

以上结果都没有取平均值，不过还是能得出一些初步的结论。比如在牵扯到输入量巨大的浮点数运算时，CUDA才会展现出优势。

" />
    <meta property="og:description" content="最近开始学习CUDA。正式开始写代码前查了一些资料，对CUDA的印象就是擅长浮点数运算，缺点就是如果数据量不足够大，就不一定比CPU快。自己尝试了一些简单的对比后稍微有些理解了。

电脑配置：i7-670HQ，GTX970m，16G。

测试使用三个CUDA官方例子中的三维向量计算函数：

inline __host__ __device__ float3 normalize(float3 v)
{
    float invLen = rsqrtf(dot(v, v));
    return v * invLen;
}
inline __host__ __device__ float length(float3 v)
{
    return sqrtf(dot(v, v));
}
inline __host__ __device__ float dot(float3 a, float3 b)
{
    return a.x * b.x + a.y * b.y + a.z * b.z;
}

其中用到的其他函数是CUDA内置的sqrtf()和基于sqrtf()的rsqrtf()：平方根和平方根倒数

extern __CUDA_MATH_CRTIMP __DEVICE_FUNCTIONS_DECL__ __device_builtin__ float __cdecl sqrtf(float) __THROW; 
inline float rsqrtf(float x)
{
    return 1.0f / sqrtf(x);
}


输入： float3 a ：(99, 99, 99);
            float3 b ：(999, 999, 999);

时间单位ms。

第一次测试：使用以上三个函数计算100万次：normalize(a); length(a-b); dot(a,b).


  
    
       
      normalize(a)
      length(a-b)
      dot(a,b)
    
  
  
    
      CPU用时
      132
      141
      32
    
    
      CUDA用时
      None
      None
      None
    
  


CUDA下直接爆内存卡死。可能是我的配置扛不住连续一百万次cudaMemcpy()。

第二次测试：换成100次。


  
    
       
      normalize(a)
      length(a-b)
      dot(a,b)
    
  
  
    
      CPU用时
      0
      0
      0
    
    
      CUDA用时
      109
      14
      16
    
  


结论：差距巨大，按照第一次测试的结果估算，这种情况下CPU比CUDA快5333倍。

第三次测试：把单独输入换成数组一次输入。以下是不同大小数组的结果。


  
    
       
      CPU nor
      CUDA nor
      CPU len
      CUDA len
      CPU dot
      CUDA dot
    
  
  
    
      100
      0
      1
      0
      0
      0
      0
    
    
      1000
      0
      1
      0
      0
      0
      0
    
    
      10000
      1
      2
      1
      2
      0
      1
    
    
      100000
      14
      21
      14
      11
      3
      13
    
    
      1000000
      139
      143
      146
      103
      34
      107
    
    
      10000000
      1395
      1455
      1460
      1064
      361
      1056
    
    
      100000000
      14254
      17737
      14661
      14809
      3420
      10722
    
  


这次的结果就有意思了。10000长度以下差别不是很大，10万次以上CUDA的length(a-b)明显比CPU快，但其他的还是比不过CPU。一亿次时爆了内存，程序卡了，CUDA的length(a-b)优势也因为爆内存而消失了。

这就说明了CUDA的好几个特点。首先是输入量大的时候，把大量变量一起传给CUDA运算会比单个传快得多，因为单个传只用了CUDA的一个线程。在数据运算量不大的时候，CUDA和CPU差距也不大，甚至CPU还全面赶超CUDA。当数据量足够大时，CUDA的length(a-b)比CPU快了差不多一半，但其他的还是慢。

从函数上看，比dot的话，整数运算CUDA总是比CPU慢。 length函数中也是调用了dot，只不过是dot的两个输入相同。CUDA算dot应该比CPU慢，可是sqrtf()让CPU的length比它自己的dot运算慢了差不多四倍。输入a，b与a-b的量级差不多，所以差别就体现在sqrtf()上。CUDA的length就和它的dot差不多，应该是因为CUDA擅长浮点数运算，所以它的length就比CPU的快。

可是刚刚的结论似乎没法解释normalize上CUDA和CPU差距不是很大的事实。normalize只是比length多了一个倒数和乘法运算。理论上应该和length差不多，实际却比length慢一半。换个角度，对比两者的dot和normalize，CUDA的这两个运算差距不是很大，normalize只比dot慢了一半。而CPU的normalize几乎用了它dot的四倍时间。其中的差异应该还是rsqrtf()的sqrtf()造成的。

试了试嵌套调用normalize，第一次嵌套就比CPU快了一点。CPU/CUDA的时间比随着嵌套次数开始增加，1.04，1.07，1.18，1.13，1.17。normalize嵌套意义可能不大，因为嵌套之后每次运算过程都一样。

以上结果都没有取平均值，不过还是能得出一些初步的结论。比如在牵扯到输入量巨大的浮点数运算时，CUDA才会展现出优势。

" />
    
    <meta name="author" content="Chaosikaros" />

    
    <meta property="og:title" content="CUDA开发笔记---向量运算对比" />
    <meta property="twitter:title" content="CUDA开发笔记---向量运算对比" />
    
  <!-- Async font loading -->
<script>
  window.WebFontConfig = {
      custom: {
          families: ['Spoqa Han Sans:100,300,400,700'],
          urls: ['https://spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css']
      },
      timeout: 60000
  };
  (function(d) {
      var wf = d.createElement('script'), s = d.scripts[0];
      wf.src = 'https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js';
      s.parentNode.insertBefore(wf, s);
  })(document);
</script>

  <!--[if lt IE 9]>
    <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <link rel="stylesheet" type="text/css" href="/blog/style.css" />
  <link rel="alternate" type="application/rss+xml" title="Chaosikaros - Blog" href="/blog/feed.xml" />
  <link rel="shortcut icon" href="https://raw.githubusercontent.com/Chaosikaros/blog/mine/images/favicon.png">
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script src="https://kit.fontawesome.com/56f7faf3f4.js"></script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>

  <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->

</head>

  <body>
    <div class="wrapper-sidebar">
  <header class="sidebar clearfix">
    <div class="site-info">
      
        <a href="/blog/" class="site-avatar"><img src="https://raw.githubusercontent.com/Chaosikaros/blog/mine/images/logo.png" /></a>
       
      <h1 class="site-name"><a href="/blog/">Chaosikaros</a></h1>
      <p class="site-description">Blog</p>
    </div>
  </header>

  <div class="navlist">
    <nav>
      
      
      <a href="/blog/">首页</a>
      
      
      
      <a href="/blog/about">关于</a>
      
      
      
      <a href="/blog/archive">归档</a>
      
      
      
      <a href="/blog/tags">标签</a>
      
      
    </nav>
  </div>

  <div class="wrapper-footer-desktop">
    <footer class="footer">
      <!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  
  
  

  

  
  <li><a href="mailto:chaosikaros@outlook.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  

  

  

  

  

  

  

  

  

</ul>



<p>Copyright (c) 2019</p>

    </footer>
  </div>
</div>

    
      <aside class="toc">
        <ul>
  <li><a href="#">CUDA开发笔记—向量运算对比</a></li>
</ul>
      </aside>
    

    <div id="main" role="main" class="wrapper-content">
      <div class="container">
        <article class="posts">
  <h1>CUDA开发笔记---向量运算对比</h1>

  <div clsss="meta">
    <span class="date">
      2020-08-27
    </span>

    <ul class="tag">
      
      <li>
        <a href="http://localhost:4000/blog/tags#CUDA">
          CUDA
        </a>
      </li>
      
    </ul>
  </div>

  <div class="entry">
    <p>最近开始学习CUDA。正式开始写代码前查了一些资料，对CUDA的印象就是擅长浮点数运算，缺点就是如果数据量不足够大，就不一定比CPU快。自己尝试了一些简单的对比后稍微有些理解了。</p>

<p>电脑配置：i7-670HQ，GTX970m，16G。</p>

<p>测试使用三个CUDA官方例子中的三维向量计算函数：</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kr">inline</span> <span class="n">__host__</span> <span class="n">__device__</span> <span class="n">float3</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">float3</span> <span class="n">v</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">float</span> <span class="n">invLen</span> <span class="o">=</span> <span class="n">rsqrtf</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span><span class="p">));</span>
    <span class="k">return</span> <span class="n">v</span> <span class="o">*</span> <span class="n">invLen</span><span class="p">;</span>
<span class="p">}</span>
<span class="kr">inline</span> <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">float</span> <span class="nf">length</span><span class="p">(</span><span class="n">float3</span> <span class="n">v</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">sqrtf</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span><span class="p">));</span>
<span class="p">}</span>
<span class="kr">inline</span> <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">float</span> <span class="nf">dot</span><span class="p">(</span><span class="n">float3</span> <span class="n">a</span><span class="p">,</span> <span class="n">float3</span> <span class="n">b</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">a</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">b</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">a</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">b</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">a</span><span class="p">.</span><span class="n">z</span> <span class="o">*</span> <span class="n">b</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>其中用到的其他函数是CUDA内置的sqrtf()和基于sqrtf()的rsqrtf()：平方根和平方根倒数</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">extern</span> <span class="n">__CUDA_MATH_CRTIMP</span> <span class="n">__DEVICE_FUNCTIONS_DECL__</span> <span class="n">__device_builtin__</span> <span class="kt">float</span> <span class="kr">__cdecl</span> <span class="n">sqrtf</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="n">__THROW</span><span class="p">;</span> 
<span class="kr">inline</span> <span class="kt">float</span> <span class="nf">rsqrtf</span><span class="p">(</span><span class="kt">float</span> <span class="n">x</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="n">f</span> <span class="o">/</span> <span class="n">sqrtf</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>输入： float3 a ：(99, 99, 99);
            float3 b ：(999, 999, 999);</p>

<p>时间单位ms。</p>

<p>第一次测试：使用以上三个函数计算100万次：normalize(a); length(a-b); dot(a,b).</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>normalize(a)</th>
      <th>length(a-b)</th>
      <th>dot(a,b)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CPU用时</td>
      <td>132</td>
      <td>141</td>
      <td>32</td>
    </tr>
    <tr>
      <td>CUDA用时</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>

<p>CUDA下直接爆内存卡死。可能是我的配置扛不住连续一百万次cudaMemcpy()。</p>

<p>第二次测试：换成100次。</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>normalize(a)</th>
      <th>length(a-b)</th>
      <th>dot(a,b)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CPU用时</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>CUDA用时</td>
      <td>109</td>
      <td>14</td>
      <td>16</td>
    </tr>
  </tbody>
</table>

<p>结论：差距巨大，按照第一次测试的结果估算，这种情况下CPU比CUDA快5333倍。</p>

<p>第三次测试：把单独输入换成数组一次输入。以下是不同大小数组的结果。</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>CPU nor</th>
      <th>CUDA nor</th>
      <th>CPU len</th>
      <th>CUDA len</th>
      <th>CPU dot</th>
      <th>CUDA dot</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>100</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>10000</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>100000</td>
      <td>14</td>
      <td>21</td>
      <td>14</td>
      <td>11</td>
      <td>3</td>
      <td>13</td>
    </tr>
    <tr>
      <td>1000000</td>
      <td>139</td>
      <td>143</td>
      <td>146</td>
      <td>103</td>
      <td>34</td>
      <td>107</td>
    </tr>
    <tr>
      <td>10000000</td>
      <td>1395</td>
      <td>1455</td>
      <td>1460</td>
      <td>1064</td>
      <td>361</td>
      <td>1056</td>
    </tr>
    <tr>
      <td>100000000</td>
      <td>14254</td>
      <td>17737</td>
      <td>14661</td>
      <td>14809</td>
      <td>3420</td>
      <td>10722</td>
    </tr>
  </tbody>
</table>

<p>这次的结果就有意思了。10000长度以下差别不是很大，10万次以上CUDA的length(a-b)明显比CPU快，但其他的还是比不过CPU。一亿次时爆了内存，程序卡了，CUDA的length(a-b)优势也因为爆内存而消失了。</p>

<p>这就说明了CUDA的好几个特点。首先是输入量大的时候，把大量变量一起传给CUDA运算会比单个传快得多，因为单个传只用了CUDA的一个线程。在数据运算量不大的时候，CUDA和CPU差距也不大，甚至CPU还全面赶超CUDA。当数据量足够大时，CUDA的length(a-b)比CPU快了差不多一半，但其他的还是慢。</p>

<p>从函数上看，比dot的话，整数运算CUDA总是比CPU慢。 length函数中也是调用了dot，只不过是dot的两个输入相同。CUDA算dot应该比CPU慢，可是sqrtf()让CPU的length比它自己的dot运算慢了差不多四倍。输入a，b与a-b的量级差不多，所以差别就体现在sqrtf()上。CUDA的length就和它的dot差不多，应该是因为CUDA擅长浮点数运算，所以它的length就比CPU的快。</p>

<p>可是刚刚的结论似乎没法解释normalize上CUDA和CPU差距不是很大的事实。normalize只是比length多了一个倒数和乘法运算。理论上应该和length差不多，实际却比length慢一半。换个角度，对比两者的dot和normalize，CUDA的这两个运算差距不是很大，normalize只比dot慢了一半。而CPU的normalize几乎用了它dot的四倍时间。其中的差异应该还是rsqrtf()的sqrtf()造成的。</p>

<p>试了试嵌套调用normalize，第一次嵌套就比CPU快了一点。CPU/CUDA的时间比随着嵌套次数开始增加，1.04，1.07，1.18，1.13，1.17。normalize嵌套意义可能不大，因为嵌套之后每次运算过程都一样。</p>

<p>以上结果都没有取平均值，不过还是能得出一些初步的结论。比如在牵扯到输入量巨大的浮点数运算时，CUDA才会展现出优势。</p>


  </div>

  
  
</article>

<div class="pagination">
  
    <span class="prev" >
      <a href="http://localhost:4000/blog/motionTracking/">
        ← 上一篇
      </a>
    </span>
  
  
</div>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-153094429-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/blog/cuda/',
		  'title': 'CUDA开发笔记---向量运算对比'
		});
	</script>
	<!-- End Google Analytics -->


  </body>

  
  <script>
    document.getElementById("main").classList.add("withtoc");
  </script>
  

  <div class="wrapper-footer-mobile">
    <footer class="footer">
      <!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  
  
  

  

  
  <li><a href="mailto:chaosikaros@outlook.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  

  

  

  

  

  

  

  

  

</ul>



<p>Copyright (c) 2019</p>

    </footer>


</html>
